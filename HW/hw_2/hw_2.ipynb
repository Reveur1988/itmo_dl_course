{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Connected to itmo_dl_course (Python 3.12.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be2b5ad0-ca7d-40eb-968b-6bb9cc7b04f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import (\n",
    "    EarlyStopping,\n",
    "    ModelCheckpoint,\n",
    "    TQDMProgressBar,\n",
    "    LearningRateMonitor,\n",
    ")\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "\n",
    "from torchmetrics import Accuracy, F1Score, AUROC, MetricCollection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d8dc4b6-00e5-40b2-8ff3-9207b923b1a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_float32_matmul_precision(\"medium\")\n",
    "pl.seed_everything(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "674c53ef-6767-4c0f-b162-829e9c34a2f0",
   "metadata": {},
   "source": [
    " ### Модификация архитектуры AlexNet\n",
    "\n",
    " В оригинальной статье AlexNet был разработан для ImageNet с изображениями 227x227x3 и имел следующие особенности:\n",
    " 1. Разделение сверточных слоев между двумя GPU из-за ограничения в 3GB памяти видеокарт того времени\n",
    " 2. Использование ReLU как функции активации - впервые для глубоких CNN\n",
    " 3. Local Response Normalization после первого и второго сверточных слоев\n",
    " 4. Overlapping pooling с размером ядра 3 и шагом 2\n",
    " 5. Data augmentation через случайные вырезки 224x224 из 256x256 изображений и отражения по горизонтали\n",
    " 6. Dropout 0.5 в первых двух полносвязных слоях\n",
    " 7. Batch size 128\n",
    " 8. SGD с momentum 0.9 и learning rate, который уменьшался вручную\n",
    "\n",
    " Изменения в нашей реализации:\n",
    "\n",
    " 1. Адаптация архитектуры под CIFAR-100 (32x32x3):\n",
    "    - Уменьшены размеры ядер и шаги сверточных слоев (kernel_size=3 вместо 11 в первом слое)\n",
    "    - Изменены размеры входов полносвязных слоев (256 * 4 * 4 вместо 256 * 6 * 6)\n",
    "    - Уменьшено количество нейронов в полносвязных слоях (1024 вместо 4096)\n",
    "\n",
    " 2. Модернизация техник нормализации и регуляризации:\n",
    "    - BatchNormalization вместо Local Response Normalization как более эффективный метод\n",
    "    - Сохранен Dropout 0.5 в полносвязных слоях\n",
    "    - Добавлен label smoothing в функцию потерь для лучшей генерализации\n",
    "\n",
    " 3. Улучшение процесса обучения:\n",
    "    - OneCycleLR scheduler вместо ручного уменьшения learning rate\n",
    "    - AdamW оптимизатор вместо SGD для более эффективной оптимизации\n",
    "    - Упрощенная аугментация данных (только RandomCrop и RandomHorizontalFlip)\n",
    "    - Gradient clipping для стабильности обучения\n",
    "    - Mixed precision training для ускорения\n",
    "\n",
    " 4. Технические изменения:\n",
    "    - Убрано разделение вычислений между GPU (оригинальное решение было вызвано техническими ограничениями)\n",
    "    - Добавлен мониторинг метрик через TensorBoard\n",
    "    - Использован фреймворк PyTorch Lightning для организации кода"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "09379a1f-5da9-434f-8988-bb5f47600278",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CIFAR100DataModule(pl.LightningDataModule):\n",
    "    def __init__(self, data_dir: str = \"./data\", batch_size: int = 128):\n",
    "        super().__init__()\n",
    "        self.data_dir = data_dir\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        # Упрощенная аугментация данных\n",
    "        self.transform_train = transforms.Compose(\n",
    "            [\n",
    "                transforms.RandomCrop(32, padding=4),\n",
    "                transforms.RandomHorizontalFlip(),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        self.transform_test = transforms.Compose(\n",
    "            [\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    def prepare_data(self):\n",
    "        torchvision.datasets.CIFAR100(self.data_dir, train=True, download=True)\n",
    "        torchvision.datasets.CIFAR100(self.data_dir, train=False, download=True)\n",
    "\n",
    "    def setup(self, stage: str):\n",
    "        if stage == \"fit\":\n",
    "            data_full = torchvision.datasets.CIFAR100(\n",
    "                self.data_dir, train=True, transform=self.transform_train\n",
    "            )\n",
    "            train_size = int(0.8 * len(data_full))\n",
    "            val_size = len(data_full) - train_size\n",
    "            self.trainset, self.valset = random_split(data_full, [train_size, val_size])\n",
    "\n",
    "        if stage == \"test\":\n",
    "            self.testset = torchvision.datasets.CIFAR100(\n",
    "                self.data_dir, train=False, transform=self.transform_test\n",
    "            )\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.trainset,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=True,\n",
    "            num_workers=os.cpu_count(),\n",
    "            persistent_workers=True,\n",
    "        )\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.valset,\n",
    "            batch_size=self.batch_size,\n",
    "            num_workers=os.cpu_count(),\n",
    "            persistent_workers=True,\n",
    "        )\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.testset,\n",
    "            batch_size=self.batch_size,\n",
    "            num_workers=os.cpu_count(),\n",
    "            persistent_workers=True,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c48af412-73a6-4898-a8b5-f5e6c7a2f4af",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImprovedAlexNet(pl.LightningModule):\n",
    "    def __init__(self, learning_rate=1e-3, label_smoothing=0.1):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(64, 192, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(192),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(192, 384, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(384),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(384, 256, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "        )\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(256 * 4 * 4, 1024),\n",
    "            nn.BatchNorm1d(1024),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(1024, 1024),\n",
    "            nn.BatchNorm1d(1024),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(1024, 100),\n",
    "        )\n",
    "\n",
    "        self.metrics = MetricCollection(\n",
    "            [\n",
    "                Accuracy(task=\"multiclass\", num_classes=100),\n",
    "                F1Score(task=\"multiclass\", num_classes=100, average=\"weighted\"),\n",
    "                AUROC(task=\"multiclass\", num_classes=100),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        self.val_metrics = self.metrics.clone(prefix=\"val_\")\n",
    "        self.test_metrics = self.metrics.clone(prefix=\"test_\")\n",
    "\n",
    "        self.criterion = nn.CrossEntropyLoss(label_smoothing=label_smoothing)\n",
    "\n",
    "        # Пример входных данных для логирования графа модели\n",
    "        self.example_input_array = torch.zeros(1, 3, 32, 32)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = self.criterion(logits, y)\n",
    "        self.log(\n",
    "            \"train_loss\", loss, on_step=True, on_epoch=True, prog_bar=True, logger=True\n",
    "        )\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = self.criterion(logits, y)\n",
    "        self.val_metrics.update(logits, y)\n",
    "        self.log(\n",
    "            \"val_loss\", loss, on_step=True, on_epoch=True, prog_bar=True, logger=True\n",
    "        )\n",
    "        return loss\n",
    "\n",
    "    def on_validation_epoch_end(self):\n",
    "        metrics = self.val_metrics.compute()\n",
    "        self.log_dict(metrics, prog_bar=True, on_epoch=True)\n",
    "        self.val_metrics.reset()\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        self.test_metrics.update(logits, y)\n",
    "\n",
    "    def on_test_epoch_end(self):\n",
    "        metrics = self.test_metrics.compute()\n",
    "        self.log_dict(metrics, prog_bar=True, on_epoch=True)\n",
    "        self.test_metrics.reset()\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.AdamW(\n",
    "            self.parameters(), lr=self.hparams.learning_rate, weight_decay=0.0005\n",
    "        )\n",
    "\n",
    "        scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
    "            optimizer,\n",
    "            max_lr=self.hparams.learning_rate,\n",
    "            epochs=self.trainer.max_epochs,\n",
    "            steps_per_epoch=len(self.trainer.datamodule.train_dataloader()),\n",
    "            pct_start=0.1,\n",
    "            div_factor=25.0,\n",
    "            final_div_factor=10000.0,\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            \"optimizer\": optimizer,\n",
    "            \"lr_scheduler\": {\n",
    "                \"scheduler\": scheduler,\n",
    "                \"interval\": \"step\",\n",
    "            },\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3aadcd43-87ac-440e-a1be-2f72ccf4ccae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/reveur/anaconda3/envs/itmo_dl_course/lib/python3.12/site-packages/lightning_fabric/connector.py:572: `precision=16` is supported for historical reasons but its usage is discouraged. Please set your precision to 16-mixed instead!\n",
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "checkpoint_path = os.path.join(\"checkpoints\", \"alexnet_cifar100\")\n",
    "os.makedirs(checkpoint_path, exist_ok=True)\n",
    "\n",
    "datamodule = CIFAR100DataModule()\n",
    "model = ImprovedAlexNet()\n",
    "\n",
    "callbacks = [\n",
    "    EarlyStopping(monitor=\"val_loss\", mode=\"min\", patience=10, min_delta=1e-4),\n",
    "    ModelCheckpoint(\n",
    "        dirpath=checkpoint_path,\n",
    "        filename=\"alexnet-cifar100-{epoch:02d}-{val_loss:.2f}\",\n",
    "        save_top_k=3,\n",
    "        mode=\"min\",\n",
    "        monitor=\"val_loss\",\n",
    "    ),\n",
    "    TQDMProgressBar(refresh_rate=20),\n",
    "    LearningRateMonitor(logging_interval=\"step\"),\n",
    "]\n",
    "\n",
    "logger = TensorBoardLogger(\n",
    "    save_dir=\"lightning_logs\",\n",
    "    name=\"improved_alexnet_cifar100\",\n",
    "    default_hp_metric=False,\n",
    ")\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=100,\n",
    "    accelerator=\"auto\",\n",
    "    devices=1,\n",
    "    callbacks=callbacks,\n",
    "    logger=logger,\n",
    "    gradient_clip_val=1.0,\n",
    "    precision=16,\n",
    "    log_every_n_steps=1,\n",
    "    enable_model_summary=True,\n",
    "    enable_progress_bar=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "751968e7-c68b-4184-a163-2cfc91b19389",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA GeForce RTX 3060 Laptop GPU') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/reveur/anaconda3/envs/itmo_dl_course/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/reveur/itmo_dl_course/HW/hw_2/checkpoints/alexnet_cifar100 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name         | Type             | Params | Mode  | In sizes       | Out sizes     \n",
      "--------------------------------------------------------------------------------------------\n",
      "0 | features     | Sequential       | 2.3 M  | train | [1, 3, 32, 32] | [1, 256, 4, 4]\n",
      "1 | classifier   | Sequential       | 5.4 M  | train | [1, 4096]      | [1, 100]      \n",
      "2 | metrics      | MetricCollection | 0      | train | ?              | ?             \n",
      "3 | val_metrics  | MetricCollection | 0      | train | ?              | ?             \n",
      "4 | test_metrics | MetricCollection | 0      | train | ?              | ?             \n",
      "5 | criterion    | CrossEntropyLoss | 0      | train | ?              | ?             \n",
      "--------------------------------------------------------------------------------------------\n",
      "7.6 M     Trainable params\n",
      "0         Non-trainable params\n",
      "7.6 M     Total params\n",
      "30.422    Total estimated model params size (MB)\n",
      "42        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/reveur/anaconda3/envs/itmo_dl_course/lib/python3.12/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)  # noqa: B028\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57: 100%|██████████| 313/313 [00:32<00:00,  9.55it/s, v_num=2, train_loss_step=1.330, val_loss_step=2.030, val_loss_epoch=2.040, val_MulticlassAccuracy=0.632, val_MulticlassF1Score=0.631, val_MulticlassAUROC=0.978, train_loss_epoch=1.160]\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(model=model, datamodule=datamodule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a46beac1-2959-41f3-b9c1-19c5cbf1f52b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/reveur/anaconda3/envs/itmo_dl_course/lib/python3.12/site-packages/pytorch_lightning/trainer/connectors/checkpoint_connector.py:145: `.test(ckpt_path=None)` was called without a model. The best model of the previous `fit` call will be used. You can pass `.test(ckpt_path='best')` to use the best model or `.test(ckpt_path='last')` to use the last model. If you pass a value, this warning will be silenced.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Restoring states from the checkpoint path at /home/reveur/itmo_dl_course/HW/hw_2/checkpoints/alexnet_cifar100/alexnet-cifar100-epoch=47-val_loss=2.03.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loaded model weights from the checkpoint at /home/reveur/itmo_dl_course/HW/hw_2/checkpoints/alexnet_cifar100/alexnet-cifar100-epoch=47-val_loss=2.03.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 79/79 [00:02<00:00, 31.56it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "  test_MulticlassAUROC      0.9829824566841125\n",
      " test_MulticlassAccuracy    0.6600000262260437\n",
      " test_MulticlassF1Score     0.6594573259353638\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'test_MulticlassAccuracy': 0.6600000262260437,\n",
       "  'test_MulticlassF1Score': 0.6594573259353638,\n",
       "  'test_MulticlassAUROC': 0.9829824566841125}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.test(datamodule=datamodule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d88b4baa-6821-4e8c-9326-78f1b9b4937e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext tensorboard\n",
    "%tensorboard --logdir lightning_logs/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "itmo_dl_course",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
